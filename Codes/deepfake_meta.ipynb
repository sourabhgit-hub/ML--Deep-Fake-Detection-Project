{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/dim4o/gender-recognizer/blob/master/Gender%20Classification.ipynb\n",
    "    https://github.com/google-research/google-research/blob/2f8d5e788c6295d71f5400806e5ed1e2a00f8f19/maml_nonexclusive/maml_classification/maml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, SelectPercentile\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Constants\n",
    "NUMBER_OF_SAMPLES = 2900\n",
    "RESIZE_SHAPE = (40, 40)\n",
    "FEMALE_CLASS = 0\n",
    "MALE_CLASS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\2nd_semester\\bigdatascience\\project\\P1\\img_align_celeba\\img_align_celeba\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_female = r\"D:\\2nd_semester\\bigdatascience\\project\\P1\\fake_faces\\\\\"\n",
    "directory_male = r\"D:\\2nd_semester\\bigdatascience\\project\\P1\\test_real_faces\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# test print for the selected names\n",
    "female_image_names = os.listdir(directory_female)\n",
    "male_image_names = os.listdir(directory_male)\n",
    "print(len(female_image_names))\n",
    "print(len(male_image_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "Image transformations\n",
    "Now I'll extract the features from the image following these actions:\n",
    "\n",
    "Get the original image\n",
    "Convet the image to grayscale\n",
    "Define the region of interests. Use haar faces to detect a face (if exists) on the image. If there is more than one face, I'll get the square with the larger area.\n",
    "Crop the square from the gray image\n",
    "Apply gaussian kernel over the cropped image to reduce the noise.\n",
    "Resize the image to 40x40px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_faces_data = None\n",
    "gender_faces_data = np.empty(shape=(0,RESIZE_SHAPE[0]*RESIZE_SHAPE[1]+1)) #64*64+1\n",
    "face_cascade = cv2.CascadeClassifier(r'D:\\2nd_semester\\bigdatascience\\project\\face_data\\face.xml')\n",
    "\n",
    "def extract_features(image_path, label):\n",
    "    \"\"\" Extracts features from a image\n",
    "    :param image_path: the path to the image\n",
    "    :param label: the label of the image\n",
    "    :return: extracted features from the image with the corresponding label as a row matrix\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    row = None\n",
    "    '''faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is not ():\n",
    "        face = sorted(faces, key=lambda x: (x[2] * x[3]), reverse=True)[0]\n",
    "        x, y, width, height = face\n",
    "        face_gray = gray[y: y + height, x: x + width]\n",
    "        \n",
    "        # apply Gaussian kernel\n",
    "        kernel = np.ones((3,3),np.float32)/9\n",
    "        face_gray = cv2.filter2D(face_gray,-1,kernel)\n",
    "        \n",
    "        resized = cv2.resize(face_gray, dsize=RESIZE_SHAPE, interpolation=cv2.INTER_CUBIC)\n",
    "        row = np.append(resized.ravel(), label)'''\n",
    "\n",
    "    return np.append((cv2.resize(gray, dsize=RESIZE_SHAPE, interpolation=cv2.INTER_CUBIC)),label)\n",
    "\n",
    "def append_data(prefix_path, label, gender_faces_data):\n",
    "    \"\"\" Appends data to a numpy array\"\"\"\n",
    "    image_names = os.listdir(prefix_path)\n",
    "    for image_path in image_names:\n",
    "        # print(image_path)\n",
    "        curr_row = extract_features(prefix_path + image_path, label)\n",
    "        if curr_row is not None:\n",
    "            gender_faces_data = np.append(gender_faces_data, [curr_row], axis=0)\n",
    "        \n",
    "    return gender_faces_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Females count: 2000\n",
      "Males count: 2000\n",
      "Gender data shape: (4000, 1601)\n"
     ]
    }
   ],
   "source": [
    "# Append the female faces\n",
    "gender_faces_data = append_data(directory_female, FEMALE_CLASS, gender_faces_data)\n",
    "female_data = gender_faces_data\n",
    "\n",
    "# Append the male faces\n",
    "gender_faces_data = append_data(directory_male, MALE_CLASS, gender_faces_data)\n",
    "\n",
    "print(\"Females count: {}\".format(female_data.shape[0]))\n",
    "print(\"Males count: {}\".format(gender_faces_data.shape[0] - female_data.shape[0]))\n",
    "print(\"Gender data shape: {}\".format(gender_faces_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 71.,  71.,  81., ...,  56.,  67.,   0.],\n",
       "       [154., 107., 122., ...,  87.,  51.,   0.],\n",
       "       [ 42.,  41.,  39., ...,  37.,  26.,   0.],\n",
       "       ...,\n",
       "       [238., 238., 238., ...,  39.,  39.,   1.],\n",
       "       [ 88., 126., 142., ...,  25.,  27.,   0.],\n",
       "       [ 59.,  54.,  62., ...,   2.,   2.,   1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suffle the data\n",
    "np.random.shuffle(gender_faces_data)\n",
    "gender_faces_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'D:\\2nd_semester\\bigdatascience\\meta\\fake_real__data_40x40_large_2.csv', gender_faces_data.astype(np.int), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1591</th>\n",
       "      <th>1592</th>\n",
       "      <th>1593</th>\n",
       "      <th>1594</th>\n",
       "      <th>1595</th>\n",
       "      <th>1596</th>\n",
       "      <th>1597</th>\n",
       "      <th>1598</th>\n",
       "      <th>1599</th>\n",
       "      <th>1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9     ...  \\\n",
       "0   71.0   71.0   81.0   89.0   91.0   94.0  107.0  114.0  117.0  123.0  ...   \n",
       "1  154.0  107.0  122.0  120.0  129.0  134.0  140.0  143.0  144.0  145.0  ...   \n",
       "2   42.0   41.0   39.0   44.0   64.0   78.0   44.0   44.0   44.0   37.0  ...   \n",
       "3  147.0  197.0  196.0  185.0  170.0  131.0  125.0  130.0  142.0  147.0  ...   \n",
       "4   87.0   73.0   96.0   93.0  112.0  131.0  143.0  145.0  141.0  141.0  ...   \n",
       "\n",
       "   1591   1592   1593   1594  1595  1596  1597   1598   1599  1600  \n",
       "0  94.0  103.0  118.0  116.0  88.0  61.0  48.0   56.0   67.0   0.0  \n",
       "1  74.0   84.0   88.0   85.0  83.0  81.0  89.0   87.0   51.0   0.0  \n",
       "2   1.0   53.0   75.0   86.0  72.0  77.0  53.0   37.0   26.0   0.0  \n",
       "3  31.0   43.0   39.0   57.0  43.0  33.0  31.0   32.0   36.0   0.0  \n",
       "4  56.0   51.0   39.0   16.0  78.0  82.0  74.0  100.0  119.0   0.0  \n",
       "\n",
       "[5 rows x 1601 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time 1-2 min, size ~200Mb\n",
    "# downloads the dataset if does not exists\n",
    "dataset_file = r'D:\\2nd_semester\\bigdatascience\\meta\\fake_real__data_40x40_large_2.csv'\n",
    "\n",
    "\n",
    "gender_faces_data = pd.read_csv(dataset_file, sep=',', header=None)\n",
    "gender_faces_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1600)\n",
      "(4000,)\n",
      "[0. 0. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# get features\n",
    "features = gender_faces_data.to_numpy()[:, :RESIZE_SHAPE[0]*RESIZE_SHAPE[1]]\n",
    "print(features.shape)\n",
    "\n",
    "# get labels\n",
    "labels = gender_faces_data.to_numpy()[:, RESIZE_SHAPE[0]*RESIZE_SHAPE[1]:].ravel() # labels = gender_faces_data.as_matrix()[:, 50*50:].ravel()\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Females count: 2000\n",
      "Males count: 2000\n",
      "{0.0: 2000, 1.0: 2000}\n"
     ]
    }
   ],
   "source": [
    "# calculates the final counts\n",
    "unique, count = np.unique(labels, return_counts=True)\n",
    "print(\"Females count: {}\".format(count[0]))\n",
    "print(\"Males count: {}\".format(count[1]))\n",
    "# out = np.histogram(labels, bins=labels)\n",
    "print(dict(zip(unique, count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of the best features\n",
    "It is difficult to find the best PCA parameters but I can make very rough approximations with something like grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (4000, 1600)\n",
      "Reducing features to 80 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.9883333333333333\n",
      "Reducing features to 140 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.99\n",
      "Reducing features to 200 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.9916666666666667\n",
      "Reducing features to 260 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.9933333333333333\n",
      "Reducing features to 320 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.9925\n",
      "Reducing features to 380 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.9925\n",
      "Reducing features to 440 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_score: 1.0\n",
      "    test_score: 0.9925\n",
      "Reducing features to 1000 ...\n",
      "    train_score: 1.0\n",
      "    test_score: 0.995\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features shape: {}\".format(features.shape))\n",
    "features_counts = [80, 140, 200, 260, 320, 380, 440, 1000]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for f_count in features_counts:\n",
    "    print(\"Reducing features to {} ...\".format(f_count))\n",
    "    pca = PCA(n_components=f_count)\n",
    "\n",
    "    pca.fit(features)\n",
    "    reduced_features = pca.transform(features)\n",
    "    \n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "        reduced_features, labels, train_size=0.7, test_size=0.3, random_state=0)\n",
    "    \n",
    "    logistic_regression = LogisticRegression(C=0.001)\n",
    "    logistic_regression.fit(features_train, labels_train)\n",
    "    \n",
    "    test_score = logistic_regression.score(features_test, labels_test)\n",
    "    train_score = logistic_regression.score(features_train, labels_train)\n",
    "    \n",
    "    print(\"    train_score: {}\".format(train_score))\n",
    "    print(\"    test_score: {}\".format(test_score))\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(features_counts, test_scores)\n",
    "plt.plot(features_counts, train_scores)\n",
    "plt.legend([\"test_score\", \"train score\"])\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "As we have seen, the data is well balanced and therefore I will choose Accuracy Score for metric. Also I will use Learning Curve, ROC curve and Confusion Matrix to analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1601)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1591</th>\n",
       "      <th>1592</th>\n",
       "      <th>1593</th>\n",
       "      <th>1594</th>\n",
       "      <th>1595</th>\n",
       "      <th>1596</th>\n",
       "      <th>1597</th>\n",
       "      <th>1598</th>\n",
       "      <th>1599</th>\n",
       "      <th>1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9     ...  \\\n",
       "0   71.0   71.0   81.0   89.0   91.0   94.0  107.0  114.0  117.0  123.0  ...   \n",
       "1  154.0  107.0  122.0  120.0  129.0  134.0  140.0  143.0  144.0  145.0  ...   \n",
       "2   42.0   41.0   39.0   44.0   64.0   78.0   44.0   44.0   44.0   37.0  ...   \n",
       "3  147.0  197.0  196.0  185.0  170.0  131.0  125.0  130.0  142.0  147.0  ...   \n",
       "4   87.0   73.0   96.0   93.0  112.0  131.0  143.0  145.0  141.0  141.0  ...   \n",
       "\n",
       "   1591   1592   1593   1594  1595  1596  1597   1598   1599  1600  \n",
       "0  94.0  103.0  118.0  116.0  88.0  61.0  48.0   56.0   67.0   0.0  \n",
       "1  74.0   84.0   88.0   85.0  83.0  81.0  89.0   87.0   51.0   0.0  \n",
       "2   1.0   53.0   75.0   86.0  72.0  77.0  53.0   37.0   26.0   0.0  \n",
       "3  31.0   43.0   39.0   57.0  43.0  33.0  31.0   32.0   36.0   0.0  \n",
       "4  56.0   51.0   39.0   16.0  78.0  82.0  74.0  100.0  119.0   0.0  \n",
       "\n",
       "[5 rows x 1601 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_faces_data = pd.read_csv(r'D:\\2nd_semester\\bigdatascience\\meta\\fake_real__data_40x40_large_2.csv', sep=',', header=None)\n",
    "\n",
    "print(gender_faces_data.shape)\n",
    "gender_faces_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1600)\n"
     ]
    }
   ],
   "source": [
    "features = gender_faces_data.to_numpy()[:, :RESIZE_SHAPE[0]*RESIZE_SHAPE[1]]\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "[0. 0. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "labels = gender_faces_data.to_numpy()[:, RESIZE_SHAPE[0]*RESIZE_SHAPE[1]:].ravel()\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression model\n",
    "Basic Logistic Regression\n",
    "I will create a pipeline for the models because it is convenient to use not only during the training but also during the use of the model. I can simply call pipeline_model.predict(...) and it will handle the PCA and Scaler transformations for the input data. It is therefore a prerequisite for fewer mistakes. On the other hand, invoking PCA and Scaler every time when creating each model will reduce performance. But for the purpose of this study, this is not so important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data to train and test set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, train_size=0.7, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pipeline for Logistic Regression\n",
    "logistic_regression_pipe = None\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "logistic_regression_pipe = Pipeline(steps=[('scaler_before', StandardScaler()), \n",
    "                          ('pca', PCA(n_components=150)),\n",
    "                          ('scaler_after', StandardScaler()),\n",
    "                          ('classifier', logistic_regression)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler_before',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=150,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('scaler_after',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=42,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit the basic Logistic Regression model\n",
    "logistic_regression_pipe.fit(features_train[:151], labels_train[:151])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic logistic regression test accuracy score: 0.975\n",
      "Basic logistic regression train accuracy score: 0.9796428571428571\n",
      "Basic logistic regression F1 score: 0.9749582637729549\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic logistic regression test accuracy score: {}\".format(\n",
    "    logistic_regression_pipe.score(features_test, labels_test)))\n",
    "print(\"Basic logistic regression train accuracy score: {}\".format(\n",
    "    logistic_regression_pipe.score(features_train, labels_train)))\n",
    "print(\"Basic logistic regression F1 score: {}\".format(\n",
    "    f1_score(labels_test, logistic_regression_pipe.predict(features_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
